{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JessicaVicentini99/AgenDay/blob/master/Lime_Experimento_Final_Classificacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCIwkz51JqCK"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV6D9lsCKPu4",
        "outputId": "421f36b3-47c1-4111-8ce1-d88cc3f84847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.32.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForPreTraining  # Or BertForPreTraining for loading pretraining heads\n"
      ],
      "metadata": {
        "id": "21J_QQr8-Bmk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hYMUbMNpJpjB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# from transformers import AutoTokenizer, TFAutoModelForSequenceClassification #TFBertForSequenceClassification\n",
        "from transformers import AutoModel, AutoTokenizer, BertTokenizer, BertModel, TFAutoModelForSequenceClassification #TFBertForSequenceClassification\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import datetime\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1kqiT5C2khl",
        "outputId": "5dd33e1f-fe81-4a67-b127-1a738973a923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NXfffpeDgOY"
      },
      "source": [
        "# Create Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xNJp0Uk0D2Cm"
      },
      "outputs": [],
      "source": [
        "def create_dir(path):\n",
        "  if not os.path.exists(path):\n",
        "    os.mkdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3j6vTwV7DmvY"
      },
      "outputs": [],
      "source": [
        "def create_directories(base_path):\n",
        "  directories = {\n",
        "    'models_path': base_path + '/models',\n",
        "    'checkpoints_path': base_path + '/checkpoints',\n",
        "    'metrics_path': base_path + '/metrics',\n",
        "    'classification_report_path': base_path + '/metrics/classification_report',\n",
        "    'graphs_path': base_path + '/metrics/graphs',\n",
        "    'history_path': base_path + '/metrics/history',\n",
        "    'lime_explanations': base_path + '/lime_explanations',\n",
        "    'lime_html': base_path + '/lime_explanations/lime_html',\n",
        "    'lime_html_1_1': base_path + '/lime_explanations/lime_html_1_1',\n",
        "    'lime_html_0_0': base_path + '/lime_explanations/lime_html_0_0',\n",
        "    'lime_html_1_0': base_path + '/lime_explanations/lime_html_1_0',\n",
        "    'lime_html_0_1': base_path + '/lime_explanations/lime_html_0_1',\n",
        "  }\n",
        "  for name, folder_path in directories.items():\n",
        "    create_dir(folder_path)\n",
        "  return directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m12SbWsiD067"
      },
      "outputs": [],
      "source": [
        "base_path = '/content/drive/MyDrive/Arquivos/Mestrado/Qualificação/Experimentos Pos Qualificacao/Fake_Br_corpus_novo_experimento'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6qD0IwUvJT_k"
      },
      "outputs": [],
      "source": [
        "create_dir(base_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PnKTW1DpEAoT"
      },
      "outputs": [],
      "source": [
        "directories = create_directories(base_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haopqh0yKhqI"
      },
      "source": [
        "## Geracao do nome do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KRDpDeWHKko3"
      },
      "outputs": [],
      "source": [
        "def generate_model_name(models_path):\n",
        "  model_files = os.listdir(models_path)\n",
        "  if model_files:\n",
        "    model_files.sort(reverse=True)\n",
        "    last_model_index = int(model_files[0].split('_')[1])\n",
        "    model_index = last_model_index + 1\n",
        "  else:\n",
        "    model_index = 1\n",
        "  timestamp = datetime.datetime.now().strftime('%d_%m_%Y-%H_%M')\n",
        "  model_save_name = f\"model_{model_index}__{timestamp}\"\n",
        "  return model_save_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "D_GnMbMeKqJ_"
      },
      "outputs": [],
      "source": [
        "def generate_metrics_files_name(model_name, directories):\n",
        "  files_name = {\n",
        "    'model': directories['models_path'] + '/' + model_name + '.h5',\n",
        "    'checkpoint': directories['checkpoints_path'] + '/' + model_name + '_checkpoint-{epoch:02d}.h5',\n",
        "    'metrics_csv': directories['metrics_path'] + '/models_metrics.csv',\n",
        "    'classification_report_txt': directories['classification_report_path'] + '/' + model_name + '.txt',\n",
        "    'classification_report_json': directories['classification_report_path'] + '/' + model_name + '.json',\n",
        "    'graph_acc': directories['graphs_path'] + '/' + model_name + '_acc.png',\n",
        "    'graph_loss': directories['graphs_path'] + '/' + model_name + '_loss.png',\n",
        "    'graph_acc_and_loss': directories['graphs_path'] + '/' + model_name + '_acc_and_loss.png',\n",
        "    'confusion_matrix': directories['graphs_path'] + '/' + model_name + '_confusion_matrix.png',\n",
        "    'history': directories['history_path'] + '/' + model_name + '_history.json',\n",
        "    'lime_explanations': directories['lime_explanations'] + '/lime_explanations.csv',\n",
        "  }\n",
        "  return files_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Hxrw4bFTK1kX"
      },
      "outputs": [],
      "source": [
        "model_save_name = generate_model_name(directories['models_path'])\n",
        "files_name = generate_metrics_files_name(model_save_name, directories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3TthUxKK954"
      },
      "source": [
        "# Model Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cAMXjsVcLACC"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'neuralmind/bert-base-portuguese-cased' #'bert-base-uncased'\n",
        "MAX_LEN = 200\n",
        "\n",
        "BATCH_SIZE = 240\n",
        "EPOCHS = 30\n",
        "LEARNING_RATE = 1e-6 #3e-5\n",
        "# LEARNING_RATE = 1e-5 #3e-5\n",
        "DROPOUT_RATE = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN66bwvXJCIW"
      },
      "source": [
        "# Load Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0FnA_nbuKDA9"
      },
      "outputs": [],
      "source": [
        "def load_dataset():\n",
        "  dataset = pd.read_csv(\n",
        "          \"/content/drive/MyDrive/Arquivos/Mestrado/Qualificação/full_text_fake_br.csv\",\n",
        "          usecols=['label', 'content'],\n",
        "          encoding='utf-8'\n",
        "        )\n",
        "  # print(dataset['label'].unique())\n",
        "  # class_mapping = {'fake': 0, 'True': 1}\n",
        "  # dataset['label'] = dataset['label'].map(class_mapping)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "odjgUQ_jOf_z"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN=(dataset['content'].str.len().max())-2"
      ],
      "metadata": {
        "id": "lKsJkQqP3Mid"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAX_LEN=200"
      ],
      "metadata": {
        "id": "eORZt0fAT56y"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAX_LEN=5000"
      ],
      "metadata": {
        "id": "8kyLgGA04hoO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PK8JHlQ5OZI1"
      },
      "outputs": [],
      "source": [
        "dataset[\"label\"]=dataset[\"label\"].astype(\"int\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4wdqTkfvKHoG",
        "outputId": "2e9db52a-da78-4e61-dc71-8d039f217011"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             content  label\n",
              "0  Ex de Luiza Brunet é ouvido em audiência do ca...      1\n",
              "1  Mercosul suspende direitos políticos da Venezu...      1\n",
              "2  Relator diz que concessão de asilo a Battisti ...      1\n",
              "3  Ele não precisa ser caçado, diz advogado do go...      1\n",
              "4  Petrobras tem interesse em encontrar parceiros...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9915cc32-d6dd-4c8b-8859-58200d39cbbf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ex de Luiza Brunet é ouvido em audiência do ca...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mercosul suspende direitos políticos da Venezu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Relator diz que concessão de asilo a Battisti ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ele não precisa ser caçado, diz advogado do go...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petrobras tem interesse em encontrar parceiros...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9915cc32-d6dd-4c8b-8859-58200d39cbbf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9915cc32-d6dd-4c8b-8859-58200d39cbbf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9915cc32-d6dd-4c8b-8859-58200d39cbbf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-df671630-8cd1-4a0f-aafc-cce8ab253221\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df671630-8cd1-4a0f-aafc-cce8ab253221')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-df671630-8cd1-4a0f-aafc-cce8ab253221 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US1Usc-IOmiO",
        "outputId": "4e96c478-a1bb-41d8-85f7-996b0e135b9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "dataset[\"label\"].unique()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHDnb0IgKe8p"
      },
      "source": [
        "## Divisao Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "fi6x0K8tKeOf"
      },
      "outputs": [],
      "source": [
        "train,test = train_test_split(dataset,test_size=0.2,random_state=42,stratify=dataset[\"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F16C5M1OKvcd",
        "outputId": "978973f3-7b29-4ceb-ab48-6aec7a6d6685"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5760, 2) (1440, 2)\n"
          ]
        }
      ],
      "source": [
        "print(train.shape,test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWxuBa1nLBUL"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ub3Tv0eLLb4t"
      },
      "outputs": [],
      "source": [
        "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "M1FQIwozlref"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr = train[\"content\"]\n"
      ],
      "metadata": {
        "id": "VTe8W_BhoHrt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "o3Abpmt1oJEY",
        "outputId": "e400ffad-4e0e-4b25-d447-7e64513a61f5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ex de Luiza Brunet é ouvido em audiência do caso no qual é acusado de agressão. Lírio Parisotto é acusado de duas lesões corporais contra a modelo: em 2015 e 2016. Outras duas testemunhas, que faltaram em audiência do ano passado, também prestaram depoimento no Fórum da Barra Funda..  O empresário Lírio Parisotto foi ouvido nesta segunda-feira (13) ao Fórum Criminal da Barra Funda, na Zona Oeste de São Paulo, em nova audiência do caso no qual ele é julgado pela acusação de agredir a ex-mulher, a atriz Luiza Brunet. Parisotto não quis falar com a imprensa. A segunda audiência de instrução durou cerca de duas horas. Além do empresário, prestaram depoimento um perito e uma mulher que presenciou uma viagem do casal para o exterior. O advogado de Parisotto, Celso Vilardi, comentou o depoimento do empresário: \"Ele tem uma versão só, nunca mentiu. Uma versão harmônica\", disse. Ele questiona as provas apresentadas pela acusação: \"Uma hora o atestado médico fala em fratura do dedo. Agora, a acusação juntou e-mail que fala em rompimento de tendão. A própria natureza da lesão vai modificando ao longo do tempo. O médico veio aqui hoje e disse que o atestado não tem o menor valor legal. Contraria todas as normas de medicinal legal e de processo.\" O advogado de Luiza Brunet, Pedro Egberto da Fonseca Neto, disse que as agressões estão comprovadas. “Não tem dúvidas das agressões nem de quem é o autor delas. Ele já tentou parar esse processo no Tribunal de Justiça de São Paulo. Não conseguiu porque está evidenciada a materialidade. Tentou no STJ em Brasília e não conseguiu.” “Não consegue explicar porque ela estava com olho roxo, costelas fraturadas, ele não consegue explicar. Então eles fazem o que fazem, jogo de cena, falam que ela que é violenta. Em 40 anos de vida pública, ela nunca teve um escândalo. Agora, do dia para a noite, virou o diabo\", disse. Sobre a agressão nos Estados Unidos, \"ele disse que ele a conteve. Mas quando perguntado sobre o olho roxo, ele disse que quem tem que explicar é ela\". No dia 29 de novembro de 2016, ocorreu a primeira audiência do caso. Naquela ocasião, Luiza Brunet foi ouvida em separado e disse que apanhou do então marido por duas vezes. Laudo e imagens de tomografia computadorizada, de junho de 2016, mostram que Luiza Brunet teve quatro costelas fraturadas. A atriz e modelo de 54 anos acusa o ex-companheiro, o empresário Lírio Parisotto, de 62, de quebrar suas costelas em 21 de maio de 2016 durante uma briga nos Estados Unidos. Segundo o laudo, foi constatada \"fratura sem desvio significativo, da porção ântero-lateral do 7o ao 10o arcos costais à direita, com formações de calos ósseos incipientes\". O laudo e as imagens das fraturas estão no processo, que é digitalizado. A divulgação do laudo com as imagens foi feita nesta semana pela revista Veja e, depois, o G1 também teve acesso ao documento . O caso que envolve as duas agressões está sob segredo judicial. Para o advogado de Parisotto, Celso Vilardi, o laudo da tomografia da coluna é questionável. \"Primeiro exame falou em nona vértebra. Depois um laudo falou em sétima, oitava, nona e décima vértebras. Então, nem os médicos particulares chegam a uma conclusão. Eu não conheço Essa tomografia não está juntada aos autos.\" O advogado de Luiza Brunet, Pedro Egberto da Fonseca Neto, rebate as críticas da defesa de Parisotto. \"O laudo já estava no processo desde o início. As imagens, o que aconteceu, é que elas foram devolvidas para a gente porque não tinha tecnologia para fazer a digitalização”, disse. Luiza ainda alega que Parisotto quebrou um dos seus dedos em 15 de dezembro de 2015 em outra discussão, desta vez em São Paulo. A defesa do empresário alega que ele tentou se defender da ex-mulher nas duas agressões de que é acusado. Como já prestou depoimento à juíza Elaine Cristina Monteiro Cavalcante, da Vara do Foro Central da Violência Doméstica e Familiar contra a Mulher, Luiza não precisou comparecer ao Fórum Criminal da Barra Funda, na Zona Oeste da capital paulista. O ex é acusado pela Promotoria de ter cometido dois crimes contra a modelo: de lesão corporal grave e leve. O empresário pode receber condenação de um ano e meio até oito anos de prisão, já que ele está sendo responsabilizado nos termos da Lei Maria da Penha, que endurece a pena. A ação penal em favor de Luiza não cobra indenização em dinheiro de Parisotto. “O Ministério Público pede apenas a punição dele [do empresário]\", falou o promotor. Na primeira audiência, outras três pessoas teriam sido ouvidas: uma testemunha de acusação (amiga da modelo) e três de defesa (ligadas a Parisotto). O advogado do empresário, Celso Vilardi, criticou em 2016 o Ministério Público por ter denunciado seu cliente por agressão contra Luiza. Ele também apontou haver contradições na versão da modelo. \"Nós já tínhamos feito uma juntada de WhastApp, texto de e-mails. Nós já tínhamos uma prova absolutamente consistente no sentido de que ela confessa que bate nele. Ela fala isso nos e-mails, os amigos falam isso nos e-mails. E, efetivamente, nós apontamos diversas contradições. As fotos que ela publicou não condizem com as daquela semana em que ela trabalhou numa novela\", disse Vilardi sobre a personagem Madá, que fez em Velho Chico, da TV Globo. A defesa de Lírio Parisotto também anexou ao processo uma troca de mensagens antigas, de período anterior às agressões, entre o empresário e a filha de Luiza Brunet, a também modelo Yasmin. Nas mensagens, a jovem teria pedido que os dois fizessem as pazes e falado que a mãe sofre com problemas psicológicos. De acordo com a acusação, o primeiro crime, de \"lesão corporal grave\", ocorreu no dia 15 de dezembro do ano passado, no apartamento do empresário em São Paulo, quando o então casal discutiu e ele quebrou um dos dedos da mão da atriz – de acordo com laudo indireto feito pelo Instituto Médico Legal (IML) a partir da radiografia que a vítima tirou à época. O segundo crime, de \"lesão corporal leve\", foi em 21 de maio de 2016, em outro apartamento do então marido, em Nova Iorque, nos Estados Unidos, segundo Luiza. No dia 29 de junho, ela procurou a Promotoria em São Paulo, cidade onde Parisotto mora, e contou que ele deu um soco no olho dela, a chutou e quebrou quatro de suas costelas – conforme constatou posteriormente laudo pericial. Em depoimento ao Ministério Público Estadual, no dia 14 de julho do ano passado, Parisotto alegou que agiu em legítima defesa para se defender de Luiza. Ele não falou com a imprensa. Luiza e Parisotto tiveram uma união estável por cinco anos, uma relação de términos e voltas. Dessa vez, os dois estão definitivamente separados. Luiza havia anexado ao processo mais de 20 fotos das lesões que alegou ter sofrido do então marido. Numa delas, que foi obtida e divulgada pelo Fantástico, ela aparece com o olho direito inchado. Em 25 de maio de 2016, a atriz havia divulgado uma foto em sua página no Facebook, quatro dias após o incidente, com parte do rosto coberto pelos cabelos e uma frase: \"A maquiagem forte esconde o hematoma da alma\". Luiza é embaixadora do Instituto Avon, que faz campanha contra a violência doméstica. Por conta da queixa de violência doméstica que a atriz prestou ao MPE contra o ex-marido, a Justiça decretou medidas de proteção para Luiza. O empresário está proibido de se aproximar e manter contato com ela.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encoded_input = tokenizer.encode_plus(text=tr[0], max_length=MAX_LEN, truncation=True, return_tensors='tf')\n"
      ],
      "metadata": {
        "id": "ZruDM5A2n_Bd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoded_input"
      ],
      "metadata": {
        "id": "gLigewSnoPqZ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feHeIvwlLjsj"
      },
      "source": [
        "# Tratamento das entradas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kmcW1BdELmqq"
      },
      "outputs": [],
      "source": [
        "# def get_masks(text, max_length):\n",
        "#     \"\"\"Mask for padding\"\"\"\n",
        "#     tokens = tokenizer.tokenize(text)\n",
        "#     length = len(tokens)\n",
        "#     if length > max_length:\n",
        "#       tokens = tokens[:max_length]\n",
        "#     tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "\n",
        "\n",
        "#     return np.asarray([1]*len(tokens) + [0] * (max_length - len(tokens)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "VWVXCYFULpcj"
      },
      "outputs": [],
      "source": [
        "# vec_get_masks = np.vectorize(get_masks, signature = '(),()->(n)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3k2zkwyGLu2a"
      },
      "outputs": [],
      "source": [
        "# def get_segments(text, max_length):\n",
        "#     \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
        "#     tokens = tokenizer.tokenize(text)\n",
        "#     length = len(tokens)\n",
        "#     if length > max_length:\n",
        "#         tokens = tokens[:max_length]\n",
        "#     tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "\n",
        "#     segments = []\n",
        "#     current_segment_id = 0\n",
        "#     with_tags = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "#     token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "#     for token in tokens:\n",
        "#         segments.append(current_segment_id)\n",
        "#         if token == \"[SEP]\":\n",
        "#             current_segment_id = 1\n",
        "#     return np.asarray(segments + [0] * (max_length - len(tokens)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "a1iR4n98L0l1"
      },
      "outputs": [],
      "source": [
        "# vec_get_segments = np.vectorize(get_segments, signature = '(),()->(n)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "nQBtu0bpL14t"
      },
      "outputs": [],
      "source": [
        "# def get_ids(text, tokenizer, max_length):\n",
        "#     \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
        "#     tokens = tokenizer.tokenize(text)\n",
        "#     length = len(tokens)\n",
        "#     if length > max_length:\n",
        "#       tokens = tokens[:max_length]\n",
        "#     tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "\n",
        "\n",
        "#     token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "#     input_ids = np.asarray(token_ids + [0] * (max_length - len(tokens)))\n",
        "#     return input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "U8-BR-C_L26o"
      },
      "outputs": [],
      "source": [
        "# vec_get_ids = np.vectorize(get_ids, signature = '(),(),()->(n)')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qFUiu9mSpfOi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "IqCOo5TaL4go"
      },
      "outputs": [],
      "source": [
        "# def prepare(text_array, tokenizer, max_length = 200):\n",
        "\n",
        "#     ids = vec_get_ids(text_array,\n",
        "#                       tokenizer,\n",
        "#                       max_length).squeeze()\n",
        "#     masks = vec_get_masks(text_array,\n",
        "#                       max_length).squeeze()\n",
        "#     segments = vec_get_segments(text_array,\n",
        "#                       max_length).squeeze()\n",
        "\n",
        "#     return ids, segments, masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IY_JBFavMAS7",
        "outputId": "a8510ec1-64c8-4dd5-e86c-2fab005fd8e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                content  label\n",
              "4264  Marqueteiro do PT está inquieto na cadeia. Ele...      0\n",
              "3482  População busca fósseis de dinossauros em Nova...      1\n",
              "4757  CHEGA! Vitória de Trump serve de aviso para a ...      0\n",
              "1942  Tribunal nega liberdade para ex-gerente de Eng...      1\n",
              "327   Chuva recorde no Rio causa 4 mortes e deixa es...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa528c34-02a1-4bdd-8d05-9f023616f839\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4264</th>\n",
              "      <td>Marqueteiro do PT está inquieto na cadeia. Ele...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3482</th>\n",
              "      <td>População busca fósseis de dinossauros em Nova...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4757</th>\n",
              "      <td>CHEGA! Vitória de Trump serve de aviso para a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1942</th>\n",
              "      <td>Tribunal nega liberdade para ex-gerente de Eng...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>Chuva recorde no Rio causa 4 mortes e deixa es...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa528c34-02a1-4bdd-8d05-9f023616f839')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fa528c34-02a1-4bdd-8d05-9f023616f839 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fa528c34-02a1-4bdd-8d05-9f023616f839');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4bdf55f1-e9ee-4099-9883-4ad635772f4b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4bdf55f1-e9ee-4099-9883-4ad635772f4b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4bdf55f1-e9ee-4099-9883-4ad635772f4b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"content\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "ww2cmMb4B3vf",
        "outputId": "b85d6607-e067-49cf-aac9-5769d4e9050f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ex de Luiza Brunet é ouvido em audiência do caso no qual é acusado de agressão. Lírio Parisotto é acusado de duas lesões corporais contra a modelo: em 2015 e 2016. Outras duas testemunhas, que faltaram em audiência do ano passado, também prestaram depoimento no Fórum da Barra Funda..  O empresário Lírio Parisotto foi ouvido nesta segunda-feira (13) ao Fórum Criminal da Barra Funda, na Zona Oeste de São Paulo, em nova audiência do caso no qual ele é julgado pela acusação de agredir a ex-mulher, a atriz Luiza Brunet. Parisotto não quis falar com a imprensa. A segunda audiência de instrução durou cerca de duas horas. Além do empresário, prestaram depoimento um perito e uma mulher que presenciou uma viagem do casal para o exterior. O advogado de Parisotto, Celso Vilardi, comentou o depoimento do empresário: \"Ele tem uma versão só, nunca mentiu. Uma versão harmônica\", disse. Ele questiona as provas apresentadas pela acusação: \"Uma hora o atestado médico fala em fratura do dedo. Agora, a acusação juntou e-mail que fala em rompimento de tendão. A própria natureza da lesão vai modificando ao longo do tempo. O médico veio aqui hoje e disse que o atestado não tem o menor valor legal. Contraria todas as normas de medicinal legal e de processo.\" O advogado de Luiza Brunet, Pedro Egberto da Fonseca Neto, disse que as agressões estão comprovadas. “Não tem dúvidas das agressões nem de quem é o autor delas. Ele já tentou parar esse processo no Tribunal de Justiça de São Paulo. Não conseguiu porque está evidenciada a materialidade. Tentou no STJ em Brasília e não conseguiu.” “Não consegue explicar porque ela estava com olho roxo, costelas fraturadas, ele não consegue explicar. Então eles fazem o que fazem, jogo de cena, falam que ela que é violenta. Em 40 anos de vida pública, ela nunca teve um escândalo. Agora, do dia para a noite, virou o diabo\", disse. Sobre a agressão nos Estados Unidos, \"ele disse que ele a conteve. Mas quando perguntado sobre o olho roxo, ele disse que quem tem que explicar é ela\". No dia 29 de novembro de 2016, ocorreu a primeira audiência do caso. Naquela ocasião, Luiza Brunet foi ouvida em separado e disse que apanhou do então marido por duas vezes. Laudo e imagens de tomografia computadorizada, de junho de 2016, mostram que Luiza Brunet teve quatro costelas fraturadas. A atriz e modelo de 54 anos acusa o ex-companheiro, o empresário Lírio Parisotto, de 62, de quebrar suas costelas em 21 de maio de 2016 durante uma briga nos Estados Unidos. Segundo o laudo, foi constatada \"fratura sem desvio significativo, da porção ântero-lateral do 7o ao 10o arcos costais à direita, com formações de calos ósseos incipientes\". O laudo e as imagens das fraturas estão no processo, que é digitalizado. A divulgação do laudo com as imagens foi feita nesta semana pela revista Veja e, depois, o G1 também teve acesso ao documento . O caso que envolve as duas agressões está sob segredo judicial. Para o advogado de Parisotto, Celso Vilardi, o laudo da tomografia da coluna é questionável. \"Primeiro exame falou em nona vértebra. Depois um laudo falou em sétima, oitava, nona e décima vértebras. Então, nem os médicos particulares chegam a uma conclusão. Eu não conheço Essa tomografia não está juntada aos autos.\" O advogado de Luiza Brunet, Pedro Egberto da Fonseca Neto, rebate as críticas da defesa de Parisotto. \"O laudo já estava no processo desde o início. As imagens, o que aconteceu, é que elas foram devolvidas para a gente porque não tinha tecnologia para fazer a digitalização”, disse. Luiza ainda alega que Parisotto quebrou um dos seus dedos em 15 de dezembro de 2015 em outra discussão, desta vez em São Paulo. A defesa do empresário alega que ele tentou se defender da ex-mulher nas duas agressões de que é acusado. Como já prestou depoimento à juíza Elaine Cristina Monteiro Cavalcante, da Vara do Foro Central da Violência Doméstica e Familiar contra a Mulher, Luiza não precisou comparecer ao Fórum Criminal da Barra Funda, na Zona Oeste da capital paulista. O ex é acusado pela Promotoria de ter cometido dois crimes contra a modelo: de lesão corporal grave e leve. O empresário pode receber condenação de um ano e meio até oito anos de prisão, já que ele está sendo responsabilizado nos termos da Lei Maria da Penha, que endurece a pena. A ação penal em favor de Luiza não cobra indenização em dinheiro de Parisotto. “O Ministério Público pede apenas a punição dele [do empresário]\", falou o promotor. Na primeira audiência, outras três pessoas teriam sido ouvidas: uma testemunha de acusação (amiga da modelo) e três de defesa (ligadas a Parisotto). O advogado do empresário, Celso Vilardi, criticou em 2016 o Ministério Público por ter denunciado seu cliente por agressão contra Luiza. Ele também apontou haver contradições na versão da modelo. \"Nós já tínhamos feito uma juntada de WhastApp, texto de e-mails. Nós já tínhamos uma prova absolutamente consistente no sentido de que ela confessa que bate nele. Ela fala isso nos e-mails, os amigos falam isso nos e-mails. E, efetivamente, nós apontamos diversas contradições. As fotos que ela publicou não condizem com as daquela semana em que ela trabalhou numa novela\", disse Vilardi sobre a personagem Madá, que fez em Velho Chico, da TV Globo. A defesa de Lírio Parisotto também anexou ao processo uma troca de mensagens antigas, de período anterior às agressões, entre o empresário e a filha de Luiza Brunet, a também modelo Yasmin. Nas mensagens, a jovem teria pedido que os dois fizessem as pazes e falado que a mãe sofre com problemas psicológicos. De acordo com a acusação, o primeiro crime, de \"lesão corporal grave\", ocorreu no dia 15 de dezembro do ano passado, no apartamento do empresário em São Paulo, quando o então casal discutiu e ele quebrou um dos dedos da mão da atriz – de acordo com laudo indireto feito pelo Instituto Médico Legal (IML) a partir da radiografia que a vítima tirou à época. O segundo crime, de \"lesão corporal leve\", foi em 21 de maio de 2016, em outro apartamento do então marido, em Nova Iorque, nos Estados Unidos, segundo Luiza. No dia 29 de junho, ela procurou a Promotoria em São Paulo, cidade onde Parisotto mora, e contou que ele deu um soco no olho dela, a chutou e quebrou quatro de suas costelas – conforme constatou posteriormente laudo pericial. Em depoimento ao Ministério Público Estadual, no dia 14 de julho do ano passado, Parisotto alegou que agiu em legítima defesa para se defender de Luiza. Ele não falou com a imprensa. Luiza e Parisotto tiveram uma união estável por cinco anos, uma relação de términos e voltas. Dessa vez, os dois estão definitivamente separados. Luiza havia anexado ao processo mais de 20 fotos das lesões que alegou ter sofrido do então marido. Numa delas, que foi obtida e divulgada pelo Fantástico, ela aparece com o olho direito inchado. Em 25 de maio de 2016, a atriz havia divulgado uma foto em sua página no Facebook, quatro dias após o incidente, com parte do rosto coberto pelos cabelos e uma frase: \"A maquiagem forte esconde o hematoma da alma\". Luiza é embaixadora do Instituto Avon, que faz campanha contra a violência doméstica. Por conta da queixa de violência doméstica que a atriz prestou ao MPE contra o ex-marido, a Justiça decretou medidas de proteção para Luiza. O empresário está proibido de se aproximar e manter contato com ela.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "MDFEhGnLL-zg"
      },
      "outputs": [],
      "source": [
        "tr = train[\"content\"]\n",
        "te = test[\"content\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MAX_LEN=15000"
      ],
      "metadata": {
        "id": "65fEjP1_fOQq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_samples_train = tokenizer.batch_encode_plus(\n",
        "    tr,\n",
        "    add_special_tokens=True,  # Adicione tokens especiais como [CLS], [SEP]\n",
        "    max_length=MAX_LEN,           # Defina o comprimento máximo desejado\n",
        "    padding=\"max_length\",     # Preencha/trunce para o comprimento máximo\n",
        "    truncation=True,          # Truncar a sequência se exceder o comprimento máximo\n",
        "    return_tensors=\"tf\"       # Retorne tensores do PyTorch\n",
        ")"
      ],
      "metadata": {
        "id": "WlKR66Axpu9E"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_samples_test = tokenizer.batch_encode_plus(\n",
        "    te,\n",
        "    add_special_tokens=True,  # Adicione tokens especiais como [CLS], [SEP]\n",
        "    max_length=MAX_LEN,           # Defina o comprimento máximo desejado\n",
        "    padding=\"max_length\",     # Preencha/trunce para o comprimento máximo\n",
        "    truncation=True,          # Truncar a sequência se exceder o comprimento máximo\n",
        "    return_tensors=\"tf\"       # Retorne tensores do PyTorch\n",
        ")"
      ],
      "metadata": {
        "id": "OEtdAKacwXHa"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoded_samples = []\n"
      ],
      "metadata": {
        "id": "WbBZAyRF-GLu"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for sample in tr:\n",
        "#     encoded_sample = tokenizer.encode_plus(\n",
        "#         sample,\n",
        "#         add_special_tokens=True,  # Adicione tokens especiais como [CLS], [SEP]\n",
        "#         max_length=MAX_LEN,           # Defina o comprimento máximo desejado\n",
        "#         padding=\"max_length\",     # Preencha/trunque para o comprimento máximo\n",
        "#         truncation=True,          # Truncar a sequência se exceder o comprimento máximo\n",
        "#         return_tensors=\"tf\"       # Retorne tensores do PyTorch\n",
        "#     )\n",
        "#     encoded_samples.append(encoded_sample)"
      ],
      "metadata": {
        "id": "WYMbLtpW9-xD"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "vLigdxH1MJ-t"
      },
      "outputs": [],
      "source": [
        "# ids_train, segments_train, masks_train = prepare(tr,\n",
        "#                                                  tokenizer, MAX_LEN)\n",
        "# ids_test, segments_test, masks_test = prepare(te,\n",
        "#                                                tokenizer, MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # ValueError: Input 0 of layer \"model_3\" is incompatible with the layer: expected shape=(None, 46074), found shape=(24, 46096)"
      ],
      "metadata": {
        "id": "E1QYrekPVj6J"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max_id_length = max([len(ids) for ids in ids_train])\n",
        "# print(\"Tamanho máximo de ids_train:\", max_id_length)"
      ],
      "metadata": {
        "id": "YPdiUbGcThGg"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max_id_length = max([len(ids) for ids in masks_train])\n",
        "# print(\"Tamanho máximo de ids_train:\", max_id_length)"
      ],
      "metadata": {
        "id": "pxb50kc6WRSJ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpjtIwYbMYWI"
      },
      "source": [
        "Token indices sequence length is longer than the specified maximum sequence length for this model (914 > 512). Running this sequence through the model will result in indexing errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF1SRMhyMb3I"
      },
      "source": [
        "# Criacao do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS1fV2QiMSRZ",
        "outputId": "fb852655-8f96-45b5-b8b6-34417d5fd474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier', 'bert/pooler/dense/kernel:0', 'bert/pooler/dense/bias:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "input_word_ids = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_word_ids')\n",
        "input_mask = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_mask')\n",
        "segment_ids = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32,name=\"segment_ids\")\n",
        "bert_model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=2\n",
        "  )\n",
        "output = bert_model([input_word_ids, input_mask, segment_ids])\n",
        "# output = output\n",
        "# output = tf.keras.layers.Dense(32,activation='relu')(output)\n",
        "# output = tf.keras.layers.Dropout(DROPOUT_RATE)(output)\n",
        "logits = output.logits  # Acessa os logits da saída da camada BERT\n",
        "probs = tf.keras.layers.Softmax()(logits)\n",
        "\n",
        "# output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "model = tf.keras.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=[probs])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ZacKLRQHNyLG"
      },
      "outputs": [],
      "source": [
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "# loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "iVsSHIXRNGcD"
      },
      "outputs": [],
      "source": [
        "# model.compile(\n",
        "#             optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE),\n",
        "#             loss='sparse_categorical_crossentropy',\n",
        "#             metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "U85SJD7UN669"
      },
      "outputs": [],
      "source": [
        "model.compile(Adam(learning_rate=LEARNING_RATE), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vse85gSRN4R-",
        "outputId": "a96ca513-f686-46fd-e552-4c31c7549dd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_word_ids (InputLayer)    [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " input_mask (InputLayer)        [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " segment_ids (InputLayer)       [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_for_sequence_classific  TFSequenceClassifie  108924674  ['input_word_ids[0][0]',         \n",
            " ation (TFBertForSequenceClassi  rOutput(loss=None,               'input_mask[0][0]',             \n",
            " fication)                      logits=(None, 2),                 'segment_ids[0][0]']            \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " softmax (Softmax)              (None, 2)            0           ['tf_bert_for_sequence_classifica\n",
            "                                                                 tion[0][0]']                     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,924,674\n",
            "Trainable params: 108,924,674\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4CFtpHFEltz"
      },
      "source": [
        "# Carregar pesos do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "9pL-YduiEpDh"
      },
      "outputs": [],
      "source": [
        "# model.load_weights('/content/drive/MyDrive/Arquivos/Mestrado/Qualificação/Fake_Br_corpus_second_experiment/models/model_2__28_05_2023-18_49.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfaxddWTMNTH"
      },
      "source": [
        "# Treinamento do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Ruxp4Kb0OGcJ"
      },
      "outputs": [],
      "source": [
        "train[\"label\"] = train[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_samples_train['input_ids']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVJ86PfSxZ_j",
        "outputId": "3fae014b-35ba-4093-a226-c43a336c1e75"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5760, 200), dtype=int32, numpy=\n",
              "array([[  101,   496,  6685, ...,  1640, 12897,   102],\n",
              "       [  101,  4150,  1163, ...,  3334,   107,   102],\n",
              "       [  101,   187, 22340, ...,   171,   771,   102],\n",
              "       ...,\n",
              "       [  101, 12075,   125, ...,   179,   368,   102],\n",
              "       [  101, 14215,  5054, ...,   125,   532,   102],\n",
              "       [  101, 11124,  1331, ..., 12385,   107,   102]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_word_ids = encoded_samples_train['input_ids']\n",
        "input_mask = encoded_samples_train['attention_mask'],\n",
        "segment_ids = encoded_samples_train['token_type_ids']"
      ],
      "metadata": {
        "id": "LyMxPCsAzt1L"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.array(train.label)"
      ],
      "metadata": {
        "id": "cbwrArNu-83S"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# labels = labels.astype(int)  # Converte para inteiros\n",
        "labels = tf.keras.utils.to_categorical(labels, num_classes=2)\n"
      ],
      "metadata": {
        "id": "2_IPq_rl--wV"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = labels.astype(int)  # Converte para inteiros\n"
      ],
      "metadata": {
        "id": "wwUz0qVDAN9m"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_samples_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaUmJ3MO_WJz",
        "outputId": "c7943fd7-9e96-4c30-cfda-348d1fab4a57"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(5760, 200), dtype=int32, numpy=\n",
              "array([[  101,   496,  6685, ...,  1640, 12897,   102],\n",
              "       [  101,  4150,  1163, ...,  3334,   107,   102],\n",
              "       [  101,   187, 22340, ...,   171,   771,   102],\n",
              "       ...,\n",
              "       [  101, 12075,   125, ...,   179,   368,   102],\n",
              "       [  101, 14215,  5054, ...,   125,   532,   102],\n",
              "       [  101, 11124,  1331, ..., 12385,   107,   102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(5760, 200), dtype=int32, numpy=\n",
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(5760, 200), dtype=int32, numpy=\n",
              "array([[1, 1, 1, ..., 1, 1, 1],\n",
              "       [1, 1, 1, ..., 1, 1, 1],\n",
              "       [1, 1, 1, ..., 1, 1, 1],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 1, 1, 1],\n",
              "       [1, 1, 1, ..., 1, 1, 1],\n",
              "       [1, 1, 1, ..., 1, 1, 1]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "cPc-FSUCO8AB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a818eb8c-ccba-4c0e-9167-9c0f5de75650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-d08df9e9ef73>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      4\u001b[0m           x={\n\u001b[1;32m      5\u001b[0m               \u001b[0;34m\"input_word_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencoded_samples_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/tf_bert_for_sequence_classification_1/bert/encoder/layer_._0/attention/self/dropout_39/dropout/random_uniform/RandomUniform' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n      yield self.process_one()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n      runner = Runner(ctx_run, result, future, yielded)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-73-d08df9e9ef73>\", line 3, in <cell line: 3>\n      history = model.fit(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1557, in run_call_with_unpacked_inputs\n      \"method added in TF 2.8. If you want the original HF compute_loss, please call \"\n    File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 1569, in call\n      outputs = self.bert(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1557, in run_call_with_unpacked_inputs\n      \"method added in TF 2.8. If you want the original HF compute_loss, please call \"\n    File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 862, in call\n      encoder_outputs = self.encoder(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 548, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 554, in call\n      layer_outputs = layer_module(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 464, in call\n      self_attention_outputs = self.attention(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 380, in call\n      self_outputs = self.self_attention(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 323, in call\n      attention_probs = self.dropout(inputs=attention_probs, training=training)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/layers/regularization/dropout.py\", line 120, in call\n      output = control_flow_util.smart_cond(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/layers/regularization/dropout.py\", line 116, in dropped_inputs\n      return self._random_generator.dropout(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 2171, in dropout\n      return tf.nn.dropout(\nNode: 'model_1/tf_bert_for_sequence_classification_1/bert/encoder/layer_._0/attention/self/dropout_39/dropout/random_uniform/RandomUniform'\nOOM when allocating tensor with shape[6,12,46082,46082] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/tf_bert_for_sequence_classification_1/bert/encoder/layer_._0/attention/self/dropout_39/dropout/random_uniform/RandomUniform}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_60731]"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(\n",
        "          x={\n",
        "              \"input_word_ids\": encoded_samples_train[\"input_ids\"],\n",
        "              \"input_mask\": encoded_samples_train[\"attention_mask\"],\n",
        "              \"segment_ids\": encoded_samples_train[\"token_type_ids\"]\n",
        "          },\n",
        "          y=train['label'],\n",
        "          validation_split=0.20,\n",
        "          epochs = EPOCHS,\n",
        "          batch_size = 6\n",
        "          )\n",
        "end_time = time.time()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH6r7aDplvGo"
      },
      "source": [
        "https://www.kaggle.com/code/andreshg/nlp-glove-bert-tf-idf-lstm-explained#8.-BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBBjg-zJibgZ"
      },
      "outputs": [],
      "source": [
        "model.save_weights(\n",
        "    '/content/drive/MyDrive/Arquivos/Mestrado/Qualificação/Fake_Br_corpus_novo_experimento/weights'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\n",
        "    '/content/drive/MyDrive/Arquivos/Mestrado/Qualificação/Fake_Br_corpus_novo_experimento/full_model'\n",
        ")"
      ],
      "metadata": {
        "id": "XONR7xU3OFOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk_y8WnBMUyh"
      },
      "source": [
        "# Avaliação do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyJ7CbqGMZfm"
      },
      "source": [
        "## Excucao do modelo no conjunto de testes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmbXXAkrPIOI"
      },
      "outputs": [],
      "source": [
        "test[\"label\"] = test[\"label\"].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0o83plf_PJDZ"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate([ids_test, masks_test, segments_test], test[\"label\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4FpTzYo_ryb"
      },
      "outputs": [],
      "source": [
        "# threshold = 0.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjqpedQtuSUV"
      },
      "outputs": [],
      "source": [
        "# y_pred = model.predict([ids_test, masks_test, segments_test])\n",
        "\n",
        "# y_pred_bool = np.argmax(y_pred, axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJVQnZ2bFoR0"
      },
      "source": [
        "# Geração de Relatorios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__bG7NZZee3D"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict([ids_test, masks_test, segments_test])\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09Q-Vn19QjE-"
      },
      "outputs": [],
      "source": [
        "y_pred_bool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJ8viKISd_6F"
      },
      "outputs": [],
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('True class')\n",
        "  plt.xlabel('Predicted class')\n",
        "  return hmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X71QCsivOVIe"
      },
      "outputs": [],
      "source": [
        "def generate_classification_report(y_pred, y_pred_bool, test, ids_test, masks_test, segments_test, files_name):\n",
        "  # y_pred = model.predict([ids_test, masks_test, segments_test])\n",
        "  # y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "\n",
        "  report = classification_report(y_pred_bool, test[\"label\"])\n",
        "  report_dict = classification_report(y_pred_bool, test[\"label\"], output_dict=True)\n",
        "  # df_report = pd.DataFrame(report_dict).transpose()\n",
        "\n",
        "  with open(files_name['classification_report_json'], 'w') as f:\n",
        "    json.dump(report_dict, f)\n",
        "\n",
        "  with open(files_name['classification_report_txt'], 'w') as f:\n",
        "    f.write(report)\n",
        "\n",
        "  print(report)\n",
        "\n",
        "  # CLASSIFICATION REPORT\n",
        "  cm = confusion_matrix(test[\"label\"], y_pred_bool)\n",
        "  df_cm = pd.DataFrame(cm, index=['0','1'], columns=['0','1'])\n",
        "  heatmap = show_confusion_matrix(df_cm)\n",
        "  heatmap.figure.savefig(files_name['confusion_matrix'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "155KXoImErNa"
      },
      "outputs": [],
      "source": [
        "generate_classification_report(y_pred, y_pred_bool, test, ids_test, masks_test, segments_test, files_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myyY6yN7G9Db"
      },
      "source": [
        "# Salvar metricas do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYHb64c7G_eg"
      },
      "outputs": [],
      "source": [
        "def save_model_metrics(model_save_name, files_name, history, start_time,\n",
        "                       end_time, epochs, batch_size, learning_rate, dropout,\n",
        "                       test_loss, test_acc, with_stop_words):\n",
        "  # Calcula o tempo de execução em segundos\n",
        "  time_seconds = round(end_time - start_time, 2)\n",
        "\n",
        "  # Calcula o tempo de execução em minutos\n",
        "  time_minutes = round(time_seconds / 60, 2)\n",
        "  metrics = {\n",
        "    'model': model_save_name,\n",
        "    'loss': history.history['loss'][-1],\n",
        "    'accuracy': history.history['accuracy'][-1],\n",
        "    'val_loss': history.history['val_loss'][-1],\n",
        "    'val_accuracy': history.history['val_accuracy'][-1],\n",
        "    'time': str(end_time - start_time),\n",
        "    'time_seconds': time_seconds,\n",
        "    'time_minutes': time_minutes,\n",
        "    'epochs': epochs,\n",
        "    'batch_size': batch_size,\n",
        "    'learning_rate': learning_rate,\n",
        "    'dropout': dropout,\n",
        "    'test_loss': test_loss,\n",
        "    'test_acc': test_acc,\n",
        "    'with_stop_words': with_stop_words\n",
        "  }\n",
        "\n",
        "  if os.path.isfile(files_name['metrics_csv']):\n",
        "      # Se o arquivo existe, leia-o em um DataFrame\n",
        "      df_metrics = pd.read_csv(files_name['metrics_csv'])\n",
        "  else:\n",
        "      # Se o arquivo não existe, crie um DataFrame vazio\n",
        "      df_metrics = pd.DataFrame()\n",
        "\n",
        "  df_metrics = df_metrics.append(metrics, ignore_index=True)\n",
        "  df_metrics.to_csv(files_name['metrics_csv'], index=False)\n",
        "\n",
        "  with open(files_name['history'], 'w') as f:\n",
        "    json.dump(history.history, f)\n",
        "\n",
        "  display(df_metrics.tail())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvSmv--mHDAb"
      },
      "outputs": [],
      "source": [
        "save_model_metrics(model_save_name, files_name, history, start_time, end_time,\n",
        "                   EPOCHS, BATCH_SIZE, LEARNING_RATE, DROPOUT_RATE, test_loss,test_acc, True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s07OPGVMh7jz"
      },
      "source": [
        "# salvar grafico do treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dblETlFkh_OK"
      },
      "outputs": [],
      "source": [
        "def save_model_graphs(model_save_name, files_name, history):\n",
        "  epochs_range = list(range(1, len(history.history['accuracy'])+1))\n",
        "  # cria o gráfico de Accuracy\n",
        "  plt.plot(epochs_range, history.history['accuracy'])\n",
        "  plt.plot(epochs_range, history.history['val_accuracy'])\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "  # Salva figura\n",
        "  plt.savefig(files_name['graph_acc'])\n",
        "  plt.show()\n",
        "\n",
        "  # cria o gráfico de Loss\n",
        "  plt.plot(epochs_range, history.history['loss'])\n",
        "  plt.plot(epochs_range, history.history['val_loss'])\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "  # Salva figura\n",
        "  plt.savefig(files_name['graph_loss'])\n",
        "  plt.show()\n",
        "\n",
        "  # Definir o tamanho da figura\n",
        "  fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
        "\n",
        "  # Plotar o gráfico de loss no primeiro subplot\n",
        "  axs[0].plot(epochs_range, history.history['loss'], label='train_loss')\n",
        "  axs[0].plot(epochs_range, history.history['val_loss'], label='val_loss')\n",
        "  axs[0].set_title('Model Loss')\n",
        "  axs[0].set_xlabel('Epoch')\n",
        "  axs[0].set_ylabel('Loss')\n",
        "  axs[0].legend()\n",
        "\n",
        "  # Plotar o gráfico de acurácia no segundo subplot\n",
        "  axs[1].plot(epochs_range, history.history['accuracy'], label='train_acc')\n",
        "  axs[1].plot(epochs_range, history.history['val_accuracy'], label='val_acc')\n",
        "  axs[1].set_title('Model Accuracy')\n",
        "  axs[1].set_xlabel('Epoch')\n",
        "  axs[1].set_ylabel('Accuracy')\n",
        "  axs[1].legend()\n",
        "\n",
        "  # Salvar a figura em um arquivo\n",
        "  plt.savefig(files_name['graph_acc_and_loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlnFh6_siE9w"
      },
      "outputs": [],
      "source": [
        "save_model_graphs(model_save_name, files_name, history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhbyI20YUfP2"
      },
      "outputs": [],
      "source": [
        "# np.shape(ids_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fY52J8_PUypv"
      },
      "outputs": [],
      "source": [
        "# y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUjjSiwk_omw"
      },
      "outputs": [],
      "source": [
        "# # y_pred_bool = np.where(y_pred >= threshold, 1, 0)\n",
        "# y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "# print(classification_report(y_pred_bool, test[\"label\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oaw1qPa7v9mX"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import confusion_matrix\n",
        "# import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0hRUHBYU9n4"
      },
      "outputs": [],
      "source": [
        "# np.shape(y_pred_bool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-5yoZwDuvDe"
      },
      "source": [
        "# LIME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szsnzZPyAf06"
      },
      "source": [
        "https://www.kaggle.com/code/arinjaypathak/fine-tuned-bert-lime-youtube-comment-sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvJmGv3butzY"
      },
      "outputs": [],
      "source": [
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtvKIpxJuxx1"
      },
      "outputs": [],
      "source": [
        "import lime\n",
        "from lime.lime_text import LimeTextExplainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMh4ckrvG5ch"
      },
      "source": [
        "## LimeTestes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRwtDYB8HARO"
      },
      "source": [
        "## Funçao de predicao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEER2lUKG79a"
      },
      "outputs": [],
      "source": [
        "def predict_proba(arr):\n",
        "    # processed=[]\n",
        "    # for i in arr:\n",
        "    #     processed.append(i)\n",
        "    id,segment,mask=prepare(arr,tokenizer,max_length=200)\n",
        "    pred=model.predict([id,mask,segment])\n",
        "    return pred\n",
        "    # id, segment, mask = prepare([arr], tokenizer, max_length=200)\n",
        "    # pred = model.predict([id, mask, segment], batch_size=1)\n",
        "    # return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITnHsuVPOiHI"
      },
      "outputs": [],
      "source": [
        "def save_lime_explain(model_save_name, files_name, pos, sample_index, sample_text, original_class, prediction_class):\n",
        "\n",
        "  metrics = {\n",
        "    'model_name': model_save_name,\n",
        "    'pos': pos,\n",
        "    'index': sample_index,\n",
        "    'real_class': original_class,\n",
        "    'pred_class': prediction_class,\n",
        "    'text': sample_text\n",
        "  }\n",
        "\n",
        "  if os.path.isfile(files_name['lime_explanations']):\n",
        "      # Se o arquivo existe, leia-o em um DataFrame\n",
        "      df_lime = pd.read_csv(files_name['lime_explanations'])\n",
        "  else:\n",
        "      # Se o arquivo não existe, crie um DataFrame vazio\n",
        "      df_lime = pd.DataFrame()\n",
        "\n",
        "  df_lime = df_lime.append(metrics, ignore_index=True)\n",
        "  df_lime.to_csv(files_name['lime_explanations'], index=False)\n",
        "  display(df_lime.tail())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cD7Md_tHR0W"
      },
      "outputs": [],
      "source": [
        "def explain_instance(directories, test, y_pred_bool, model_save_name, files_name):\n",
        "  class_names = [0, 1]\n",
        "  explainer = LimeTextExplainer(class_names=class_names)\n",
        "  i = 0\n",
        "  for index, row in test.iterrows():\n",
        "    if i <= 682:\n",
        "      i = i + 1\n",
        "      continue\n",
        "    file_name = '/' + model_save_name + '_' + str(i) + '_pos_' + str(index) + '_index_'+ str(int(row['label'])) + '_orig_class_'+ str(y_pred_bool[i]) +'pred_class__lime_explain'\n",
        "    html_path = 'lime_html_' +  str(int(row['label'])) + '_' + str(y_pred_bool[i])\n",
        "    # explicando instancia\n",
        "    exp = explainer.explain_instance(row['content'], predict_proba)\n",
        "    exp.show_in_notebook(text=True)\n",
        "    # Salvando html do lime\n",
        "    exp.save_to_file(directories[html_path] + file_name + '.html')\n",
        "    # salvando explicancao como csv\n",
        "    result_list = exp.as_list()\n",
        "    csv_file_name = directories[html_path] + file_name + '.csv'\n",
        "    with open(csv_file_name, mode='w', newline='') as result_file:\n",
        "      writer = csv.writer(result_file)\n",
        "      writer.writerows(result_list)\n",
        "    # salvando texto e predicao e classe real no csv com todas as amostras\n",
        "    save_lime_explain(model_save_name, files_name, i, index, row['content'], row['label'], y_pred_bool[i])\n",
        "    i = i + 1\n",
        "    print(i)\n",
        "    print('-------------------------------------')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oj7CM_iVN9bf"
      },
      "outputs": [],
      "source": [
        "explain_instance(directories, test, y_pred_bool, model_save_name, files_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-S5kWNPNo9B"
      },
      "outputs": [],
      "source": [
        "def explain_instance(explainer, directories, test):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-rR6dviG1En"
      },
      "source": [
        "# experimentos de teste Lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4UfrkWoGzuQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jZ5-YcQAmhU"
      },
      "outputs": [],
      "source": [
        "# y_pred = model.predict([ids_test, masks_test, segments_test])\n",
        "# row_index = dataset.loc[dataset['label'] == 0].index[0]\n",
        "# row = dataset.loc[row_index, :]\n",
        "# ids_train, segments_train, masks_train = prepare(tr,\n",
        "#                                                  tokenizer, MAX_LEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4Vl0KYpGfq4"
      },
      "source": [
        "## funcao de predicao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_hj8XZmAoyT"
      },
      "outputs": [],
      "source": [
        "def predict_proba_test(arr):\n",
        "    # processed=[]\n",
        "    # for i in arr:\n",
        "    #     processed.append(i)\n",
        "    id,segment,mask=prepare(arr,tokenizer,max_length=200)\n",
        "    pred=model.predict([id,mask,segment])\n",
        "    return pred\n",
        "    # id, segment, mask = prepare([arr], tokenizer, max_length=200)\n",
        "    # pred = model.predict([id, mask, segment], batch_size=1)\n",
        "    # return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wxGoIpYYZ6l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smDj5H19YCCf"
      },
      "outputs": [],
      "source": [
        "row_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_D3fO_bX-DV"
      },
      "outputs": [],
      "source": [
        "dataset.iloc[4,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNmncCZgX9I0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09ZTSuojA2_m"
      },
      "outputs": [],
      "source": [
        "# sample_text = dataset.iloc[4,:]\n",
        "sample_text = dataset['content'][4]\n",
        "sample_text = dataset['content'][4]\n",
        "      # dataset['content'][3600]\n",
        "\n",
        "samples = [\n",
        "     dataset['content'][4],\n",
        "     dataset['content'][3600]\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uql1kYkQJbbr"
      },
      "outputs": [],
      "source": [
        "samples = [\n",
        "     dataset['content'][6660],\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjZ9JCcgK3_R"
      },
      "outputs": [],
      "source": [
        "dataset.iloc[3600,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiWPsmtsIKEY"
      },
      "outputs": [],
      "source": [
        "test['content'][6660]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-wy4JT4IGwZ"
      },
      "outputs": [],
      "source": [
        "test[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "punICj3TC4DQ"
      },
      "outputs": [],
      "source": [
        "resp = predict_proba_test(samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NZcvemhY4et"
      },
      "outputs": [],
      "source": [
        "resp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTlYQOZZEfTf"
      },
      "outputs": [],
      "source": [
        "resp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aPl-zsCrxrT"
      },
      "outputs": [],
      "source": [
        "resp = predict_proba(dataset['content'][4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXtwWI0HT8Eh"
      },
      "outputs": [],
      "source": [
        "# test = np.where(resp >= threshold, 1, 0)\n",
        "np.argmax(resp, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSDrVZCbGoxT"
      },
      "source": [
        "## instanciando explainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PZZnVLtRqFk"
      },
      "outputs": [],
      "source": [
        "class_names = [0, 1]\n",
        "explainer = LimeTextExplainer(class_names=class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5EI21FpA94P"
      },
      "outputs": [],
      "source": [
        "explainer.explain_instance(dataset['content'][3600],predict_proba).show_in_notebook(text=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CHvFtX-bmaH"
      },
      "outputs": [],
      "source": [
        "explainer.explain_instance(dataset['content'][4],predict_proba).show_in_notebook(text=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "mount_file_id": "1mJaMp0A156CKm4RCepk7JBxea3BQkWJ1",
      "authorship_tag": "ABX9TyMcmxw/atJ3YdeUuz/SWJiD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}